{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from unity_environment_wrapper import unity_env, str_numbers\n",
    "from Multi_Agent_DDPG import Multi_MA_DDPG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_state6(self,state,prev_state=None):\n",
    "    state = np.reshape(state,(3,8))[:,0:6]\n",
    "    if prev_state is None:\n",
    "        state[0,:] = state[2,:]\n",
    "        state[1,:] = state[2,:]\n",
    "    else:\n",
    "        state[0,:] = prev_state[6:12]\n",
    "        state[1,:] = prev_state[12:]\n",
    "        #if abs(state[2,0]-state[1,0]) < 1e-6:\n",
    "        #    state[2,2] = 0.0\n",
    "        #if abs(state[2,1]-state[1,1]) < 1e-6:\n",
    "        #    state[2,3] = 0.0\n",
    "    return state.reshape(-1)\n",
    "\n",
    "def fix_state4(self,state,prev_state=None):\n",
    "    state = np.reshape(state,(3,8))[:,[0,1,4,5]]\n",
    "    if prev_state is None:\n",
    "        state[0,:] = state[2,:]\n",
    "        state[1,:] = state[2,:]\n",
    "    else:\n",
    "        state[0,:] = prev_state[4:8]\n",
    "        state[1,:] = prev_state[8:]\n",
    "    return state.reshape(-1)\n",
    "\n",
    "def modify_batch6(self):\n",
    "    if self.duplicate_augmented_batch > 1:\n",
    "        ind_start = self.batch_size\n",
    "        ind_end = self.batch_size*2\n",
    "        self.states[ind_start:ind_end,:,[4,10,16]] *= -1\n",
    "        self.next_states[ind_start:ind_end,:,[4,10,16]] *= -1\n",
    "        self.states[ind_start:ind_end,[0,1],:]      = self.states[ind_start:ind_end,[1,0],:]\n",
    "        self.actions[ind_start:ind_end,[0,1],:]     = self.actions[ind_start:ind_end,[1,0],:]\n",
    "        self.next_states[ind_start:ind_end,[0,1],:] = self.next_states[ind_start:ind_end,[1,0],:]\n",
    "        if self.rewards.shape[1] > 1:\n",
    "            self.rewards[ind_start:ind_end,[0,1]]   = self.rewards[ind_start:ind_end,[1,0]]\n",
    "        if self.dones.shape[1] > 1:\n",
    "            self.dones[ind_start:ind_end,[0,1]]     = self.dones[ind_start:ind_end,[1,0]]\n",
    "\n",
    "def modify_batch4(self):\n",
    "    if self.duplicate_augmented_batch > 1:\n",
    "        ind_start = self.batch_size\n",
    "        ind_end = self.batch_size*2\n",
    "        self.states[ind_start:ind_end,:,[2,6,10]] *= -1\n",
    "        self.next_states[ind_start:ind_end,:,[2,6,10]] *= -1\n",
    "        self.states[ind_start:ind_end,[0,1],:]      = self.states[ind_start:ind_end,[1,0],:]\n",
    "        self.actions[ind_start:ind_end,[0,1],:]     = self.actions[ind_start:ind_end,[1,0],:]\n",
    "        self.next_states[ind_start:ind_end,[0,1],:] = self.next_states[ind_start:ind_end,[1,0],:]\n",
    "        if self.rewards.shape[1] > 1:\n",
    "            self.rewards[ind_start:ind_end,[0,1]]   = self.rewards[ind_start:ind_end,[1,0]]\n",
    "        if self.dones.shape[1] > 1:\n",
    "            self.dones[ind_start:ind_end,[0,1]]     = self.dones[ind_start:ind_end,[1,0]]\n",
    "\n",
    "def modify_batch4_abs(self):\n",
    "    np.abs(self.states[:,:,[2,6,10]], out=self.states[:,:,[2,6,10]])\n",
    "    np.abs(self.next_states[:,:,[2,6,10]], out=self.next_states[:,:,[2,6,10]])\n",
    "    if self.duplicate_augmented_batch > 1:\n",
    "        ind_start = self.batch_size\n",
    "        ind_end = self.batch_size*2\n",
    "        self.states[ind_start:ind_end,[0,1],:]      = self.states[ind_start:ind_end,[1,0],:]\n",
    "        self.actions[ind_start:ind_end,[0,1],:]     = self.actions[ind_start:ind_end,[1,0],:]\n",
    "        self.next_states[ind_start:ind_end,[0,1],:] = self.next_states[ind_start:ind_end,[1,0],:]\n",
    "        if self.rewards.shape[1] > 1:\n",
    "            self.rewards[ind_start:ind_end,[0,1]]   = self.rewards[ind_start:ind_end,[1,0]]\n",
    "        if self.dones.shape[1] > 1:\n",
    "            self.dones[ind_start:ind_end,[0,1]]     = self.dones[ind_start:ind_end,[1,0]]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring Unity environment...\n",
      "Selected brain name:  TennisBrain\n",
      "Selected brain:       Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n",
      "Number of actions:    2\n",
      "Number of agents:     2\n",
      "States have shape:    (24,)\n",
      "State of agent 0 look like:\n",
      " [  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000  -6.638  -1.500  -0.000   0.000   6.001   6.000  -0.000   0.000]\n",
      "State of agent 1 look like:\n",
      " [  0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000   0.000  -7.079  -1.500   0.000   0.000  -6.001   6.000   0.000   0.000]\n",
      "Initializing DDPG_Agent with PyTorch device named: cuda:0\n",
      "replay_buffer_size = 1000000\n",
      "replay_batch_size  = 128\n",
      "seed               = 1\n",
      "gamma              = 0.95\n",
      "tau                = 0.001\n",
      "update_every       = 4\n",
      "update_times       = 1\n",
      "lr_actor           = 1e-05\n",
      "lr_critic          = 1e-06\n",
      "actor_clip_grad    = None\n",
      "critic_clip_grad   = None\n",
      "noise_sigma        = 0.2\n",
      "noise_theta        = 0.1\n",
      "no_reward_value    = -0.001\n",
      "actor_arch         = ['b', 128, 'b', 'r', 64, 'b', 'r']\n",
      "critic_arch        = [['b', 128, 'b', 'r', 64], ['b', 64, 'b', 'r', 32], ['b', 'r', 64, 'b', 'r', 1]]\n",
      "Initializing Actor to:\n",
      " ModuleListUtil(\n",
      "  (0): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): Linear(in_features=24, out_features=128, bias=True)\n",
      "  (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): LeakyReLU(negative_slope=0.01)\n",
      "  (7): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "Initializing Critic state layers to:\n",
      " ModuleListUtil(\n",
      "  (0): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): Linear(in_features=24, out_features=128, bias=True)\n",
      "  (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      ")\n",
      "Initializing Critic action layers to:\n",
      " ModuleListUtil(\n",
      "  (0): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=64, out_features=32, bias=True)\n",
      ")\n",
      "Initializing Critic combine layers to:\n",
      " ModuleListUtil(\n",
      "  (0): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=192, out_features=64, bias=True)\n",
      "  (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (4): LeakyReLU(negative_slope=0.01)\n",
      "  (5): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "env = unity_env(file_name=\"Tennis_Windows_x86_64/Tennis.exe\", no_graphics=True, score_goal=0.5, verbose_level=1,\\\n",
    "                set_modify_state=None) # fix_state4\n",
    "\n",
    "    \n",
    "agent = Multi_MA_DDPG(state_shape = env.state_shape, action_size = env.action_size, num_agents=env.num_agents,\\\n",
    "                       seed=1,\\\n",
    "                       replay_buffer_size = int(1e6),\\\n",
    "                       replay_batch_size =128,\\\n",
    "                      duplicate_augmented_times=1,\\\n",
    "                      set_modify_batch=None,\\\n",
    "                      # modify_batch4_abs\n",
    "                       update_every=4,\\\n",
    "                       update_times=1,\\\n",
    "                       lr_actor=1e-5,\\\n",
    "                       lr_critic=1e-6,\\\n",
    "                       noise_sigma=0.2,\\\n",
    "                       noise_theta=0.1,\\\n",
    "                       no_reward_value = -0.001,\\\n",
    "                      # -0.02,\\\n",
    "                       actor_arch = ['b',128,'b','r',64,'b','r'],\\\n",
    "                       critic_arch = [['b',128,'b','r',64],['b',64,'b','r',32],['b','r',64,'b','r',1]],\\\n",
    "                       gamma = 0.95,\\\n",
    "                       use_cuda=True, verbose_level=2)\n",
    "\n",
    "output_name = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DDPG agent:\n",
      "output_filename    = results\n",
      "noise_minimal      = 0.01\n",
      "noise_decay        = 0.995\n",
      "num_episode_search = 500\n",
      "max_num_episodes   = 10000\n",
      "score_window_size  = 100\n",
      "Episode 600 curr=-0.01 \tAverage=0.000 Stdev=0.000 Composite=0.000 Max=0.000 \tbest len=8520 long_term len=0 highest=-0.01 \n",
      "No more improvements. End of training.\n"
     ]
    }
   ],
   "source": [
    "agent.reset()\n",
    "all_scores, best_test_score, best_test_average, best_test_stdev = env.train(agent,output_name,num_episode_search=500,noise_decay=0.995)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(all_scores)), all_scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Train Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Actor:\n\tUnexpected key(s) in state_dict: \"layers_list.8.weight\", \"layers_list.8.bias\", \"layers_list.8.running_mean\", \"layers_list.8.running_var\", \"layers_list.8.num_batches_tracked\", \"layers_list.10.weight\", \"layers_list.10.bias\". \n\tsize mismatch for layers_list.0.weight: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for layers_list.0.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for layers_list.0.running_mean: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for layers_list.0.running_var: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for layers_list.1.weight: copying a param with shape torch.Size([256, 12]) from checkpoint, the shape in current model is torch.Size([128, 24]).\n\tsize mismatch for layers_list.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.4.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for layers_list.4.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.5.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.5.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.5.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.5.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.7.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([2, 64]).\n\tsize mismatch for layers_list.7.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c67363b75f21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_composite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_stdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_agent_on_many_episodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Final Test scores on {} episodes:\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean score:    \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Std.Dev. score:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_stdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\projects\\udacity\\MatkotRL\\Multi_Agent_DDPG.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_local\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"actor_local.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m    \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"actor_target.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"actor_optimizer.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 847\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    848\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Actor:\n\tUnexpected key(s) in state_dict: \"layers_list.8.weight\", \"layers_list.8.bias\", \"layers_list.8.running_mean\", \"layers_list.8.running_var\", \"layers_list.8.num_batches_tracked\", \"layers_list.10.weight\", \"layers_list.10.bias\". \n\tsize mismatch for layers_list.0.weight: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for layers_list.0.bias: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for layers_list.0.running_mean: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for layers_list.0.running_var: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for layers_list.1.weight: copying a param with shape torch.Size([256, 12]) from checkpoint, the shape in current model is torch.Size([128, 24]).\n\tsize mismatch for layers_list.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers_list.4.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for layers_list.4.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.5.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.5.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.5.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.5.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layers_list.7.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([2, 64]).\n\tsize mismatch for layers_list.7.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "agent.load(output_name)\n",
    "test_composite, test_mean, test_stdev, test_scores = env.test_agent_on_many_episodes(agent)\n",
    "print(\"Final Test scores on {} episodes:\".format(len(test_scores)))\n",
    "print(\"Mean score:    \",test_mean)\n",
    "print(\"Std.Dev. score:\",test_stdev)\n",
    "\n",
    "env.test_agent_on_single_episode(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
